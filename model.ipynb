{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f20247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import env\n",
    "import prepare\n",
    "import acquire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ea821",
   "metadata": {},
   "source": [
    "# Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6331ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 15), (143, 15), (143, 15))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import titanic dataset, run our prepare functions, split into train/validate/test, and validate size of df's\n",
    "df = acquire.get_titanic_data()\n",
    "df = prepare.prep_titanic(df)\n",
    "tit_train, tit_validate, tit_test = prepare.my_split(df, target='survived')\n",
    "tit_train.shape, tit_validate.shape, tit_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671179d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   sex   age  sibsp  parch    fare embarked  embark_town  \\\n",
       "870         0       3  male  26.0      0      0  7.8958        S  Southampton   \n",
       "\n",
       "     alone  sex_female  sex_male  embark_town_Cherbourg  \\\n",
       "870      1           0         1                      0   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  \n",
       "870                       0                        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tit_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f643b0c",
   "metadata": {},
   "source": [
    "## What is your baseline prediction?  What is your baseline accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7509f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common value (our baseline) is: 0\n",
      "The rate of occurance (our baseline accuracy) is: 59.624413145539904\n"
     ]
    }
   ],
   "source": [
    "# find the most common condition for our target to determine baseline.  It's rate of occurance is the accuracy of \n",
    "# our baseline\n",
    "print('The most common value (our baseline) is:',tit_train.survived.value_counts().idxmax())\n",
    "print('The rate of occurance (our baseline accuracy) is:', len(tit_train[tit_train.survived == 0]) / len(tit_train) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b6f783",
   "metadata": {},
   "source": [
    "# Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c2b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each of our datasets into X and y \n",
    "\n",
    "X_train = tit_train.drop(columns=['survived', 'sex', 'embarked', 'embark_town', 'sex_female', 'embark_town_Cherbourg'])\n",
    "y_train = tit_train.survived\n",
    "\n",
    "X_validate = tit_validate.drop(columns=['survived', 'sex', 'embarked', 'embark_town', 'sex_female', 'embark_town_Cherbourg'])\n",
    "y_validate = tit_validate.survived\n",
    "\n",
    "X_test = tit_test.drop(columns=['survived', 'sex', 'embarked', 'embark_town', 'sex_female', 'embark_town_Cherbourg'])\n",
    "y_test = tit_test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aba0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred_prob = clf.predict_proba(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20563f",
   "metadata": {},
   "source": [
    "## Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a449ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 99.30%\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "print(f'training score: {clf.score(X_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5f23356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "0  254    0\n",
      "1    3  169\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(pd.DataFrame(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5d7d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       254\n",
      "           1       1.00      0.98      0.99       172\n",
      "\n",
      "    accuracy                           0.99       426\n",
      "   macro avg       0.99      0.99      0.99       426\n",
      "weighted avg       0.99      0.99      0.99       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c5722",
   "metadata": {},
   "source": [
    "## Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72e38eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Accuracy score is:  0.9929577464788732\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print('------- Model 1 -----------')\n",
    "print('Accuracy score is: ', accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "133ffbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "True positive rate is: 0.596244131455399\n",
      "False positive rate is 0.0\n",
      "True negative rate is 0.3967136150234742\n",
      "False negative rate is 0.007042253521126761\n"
     ]
    }
   ],
   "source": [
    "# true positive rate, false positive rate, true negative rate, false negative rate\n",
    "tp = cm[0,0]\n",
    "tn = cm[1,1]\n",
    "fp = cm[0,1]\n",
    "fn = cm[1,0]\n",
    "print('------- Model 1 -----------')\n",
    "print('True positive rate is:', tp/(tp+tn+fp+fn))\n",
    "print('False positive rate is', fp/(tp+tn+fp+fn))\n",
    "print('True negative rate is', tn/(tp+tn+fp+fn))\n",
    "print('False negative rate is', fn/(tp+tn+fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a887eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Precision is:  1.0\n",
      "Recall is: 0.9825581395348837\n",
      "f1 score is: 0.9912023460410557\n",
      "Support is 0: 254\n",
      "           1: 172\n"
     ]
    }
   ],
   "source": [
    "# precision, recall, f1-score and support\n",
    "print('------- Model 1 -----------')\n",
    "print('Precision is: ', precision_score(y_train, y_pred))\n",
    "print('Recall is:', recall_score(y_train, y_pred))\n",
    "print('f1 score is:', f1_score(y_train, y_pred))\n",
    "print('Support is 0:', tp+fp)\n",
    "print('           1:', tn+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c2ab4",
   "metadata": {},
   "source": [
    "## Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5a358b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing max depth to 5\n",
    "clf2 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(X_train)\n",
    "y_pred_prob2 = clf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8f2a59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "training score for model2: 85.68%\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "print('------- Model 2 -----------')\n",
    "print(f'training score for model2: {clf2.score(X_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c341ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "0  230   24\n",
      "1   37  135\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm2 = confusion_matrix(y_train, y_pred2)\n",
    "print(pd.DataFrame(cm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d53239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88       254\n",
      "           1       0.85      0.78      0.82       172\n",
      "\n",
      "    accuracy                           0.86       426\n",
      "   macro avg       0.86      0.85      0.85       426\n",
      "weighted avg       0.86      0.86      0.86       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print('------- Model 2 -----------')\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8c4345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "Accuracy score for model 2 is:  0.8568075117370892\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print('------- Model 2 -----------')\n",
    "print('Accuracy score for model 2 is: ', accuracy_score(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cc2f30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "True positive rate is: 0.539906103286385\n",
      "False positive rate is 0.056338028169014086\n",
      "True negative rate is 0.31690140845070425\n",
      "False negative rate is 0.08685446009389672\n"
     ]
    }
   ],
   "source": [
    "# true positive rate, false positive rate, true negative rate, false negative rate\n",
    "tp2 = cm2[0,0]\n",
    "tn2 = cm2[1,1]\n",
    "fp2 = cm2[0,1]\n",
    "fn2 = cm2[1,0]\n",
    "\n",
    "print('------- Model 2 -----------')\n",
    "print('True positive rate is:', tp2/(tp2+tn2+fp2+fn2))\n",
    "print('False positive rate is', fp2/(tp2+tn2+fp2+fn2))\n",
    "print('True negative rate is', tn2/(tp2+tn2+fp2+fn2))\n",
    "print('False negative rate is', fn2/(tp2+tn2+fp2+fn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3edb47b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "Precision is:  0.8490566037735849\n",
      "Recall is: 0.7848837209302325\n",
      "f1 score is: 0.8157099697885195\n",
      "Support is 0: 254\n",
      "           1: 172\n"
     ]
    }
   ],
   "source": [
    "# precision, recall, f1-score and support\n",
    "print('------- Model 2 -----------')\n",
    "print('Precision is: ', precision_score(y_train, y_pred2))\n",
    "print('Recall is:', recall_score(y_train, y_pred2))\n",
    "print('f1 score is:', f1_score(y_train, y_pred2))\n",
    "print('Support is 0:', tp2+fp2)\n",
    "print('           1:', tn2+fn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18a469",
   "metadata": {},
   "source": [
    "## Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5144c74",
   "metadata": {},
   "source": [
    "Model 1 performs better when evaluating performance against the in-sample (training) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b083be97",
   "metadata": {},
   "source": [
    "## Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7348db8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.76\n",
      "\n",
      "------- Model 2 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.82\n"
     ]
    }
   ],
   "source": [
    "print('------- Model 1 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))\n",
    "print('')\n",
    "print('------- Model 2 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf2.score(X_validate, y_validate)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fdda672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81        85\n",
      "           1       0.76      0.60      0.67        58\n",
      "\n",
      "    accuracy                           0.76       143\n",
      "   macro avg       0.76      0.74      0.74       143\n",
      "weighted avg       0.76      0.76      0.76       143\n",
      "\n",
      "------- Model 2 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.92      0.86        85\n",
      "           1       0.85      0.67      0.75        58\n",
      "\n",
      "    accuracy                           0.82       143\n",
      "   macro avg       0.83      0.80      0.80       143\n",
      "weighted avg       0.82      0.82      0.81       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "y_pred = clf.predict(X_validate)\n",
    "y_pred2 = clf2.predict(X_validate)\n",
    "\n",
    "print('------- Model 1 -----------')\n",
    "print(classification_report(y_validate, y_pred))\n",
    "\n",
    "print('------- Model 2 -----------')\n",
    "print(classification_report(y_validate, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fa07e",
   "metadata": {},
   "source": [
    "Model 2 performs slightly better with a max depth of 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd126bc",
   "metadata": {},
   "source": [
    "# Work through these same exercises using the Telco dataset.\n",
    "    ## building two models simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e93865fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 5), (30, 5), (30, 5))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get and prepare iris data\n",
    "iris = acquire.get_iris_data()\n",
    "iris = prepare.prep_iris(iris)\n",
    "i_train, i_validate, i_test = prepare.my_split(iris, target='species')\n",
    "i_train.shape, i_validate.shape, i_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62f40bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common value (our baseline) is: setosa\n",
      "The rate of occurance (our baseline accuracy) is: 33.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# find the baseline and the baseline accuracy\n",
    "baseline = i_train.species.value_counts().idxmax()\n",
    "print('The most common value (our baseline) is:', baseline)\n",
    "print('The rate of occurance (our baseline accuracy) is:', len(i_train[i_train.species == baseline]) / len(i_train) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4dc9a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each of our datasets into X and y \n",
    "\n",
    "X_train = i_train.drop(columns=('species'))\n",
    "y_train = i_train.species\n",
    "\n",
    "X_validate = i_validate.drop(columns=('species'))\n",
    "y_validate = i_validate.species\n",
    "\n",
    "X_test = i_test.drop(columns='species')\n",
    "y_test = i_test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e85026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the models\n",
    "clf1 = DecisionTreeClassifier(max_depth=8)\n",
    "clf2 = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf1.predict(X_train)\n",
    "y_pred2 = clf2.predict(X_train)\n",
    "\n",
    "y_pred_prob1 = clf1.predict_proba(X_train)\n",
    "y_pred_prob2 = clf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82afab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 training score: 100.00%\n",
      "Model 2 training score: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "print(f'Model 1 training score: {clf1.score(X_train, y_train):.2%}')\n",
    "print(f'Model 2 training score: {clf2.score(X_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31c4da7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Model 1----\n",
      "    0   1   2\n",
      "0  30   0   0\n",
      "1   0  30   0\n",
      "2   0   0  30\n",
      "\n",
      "----Model 2----\n",
      "    0   1   2\n",
      "0  30   0   0\n",
      "1   0  30   0\n",
      "2   0   0  30\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm1 = confusion_matrix(y_train, y_pred1)\n",
    "cm2 = confusion_matrix(y_train, y_pred2)\n",
    "print('----Model 1----')\n",
    "print(pd.DataFrame(cm1))\n",
    "print('')\n",
    "print('----Model 2----')\n",
    "print(pd.DataFrame(cm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3325df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        30\n",
      "  versicolor       1.00      1.00      1.00        30\n",
      "   virginica       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        30\n",
      "  versicolor       1.00      1.00      1.00        30\n",
      "   virginica       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred1))\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c6a07",
   "metadata": {},
   "source": [
    "## ...and comparing with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2c6462da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.93\n",
      "\n",
      "------- Model 2 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.93\n"
     ]
    }
   ],
   "source": [
    "print('------- Model 1 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf1.score(X_validate, y_validate)))\n",
    "print('')\n",
    "print('------- Model 2 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8173100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.80      0.89        10\n",
      "   virginica       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "------- Model 2 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.80      0.89        10\n",
      "   virginica       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "y_pred1 = clf1.predict(X_validate)\n",
    "y_pred2 = clf2.predict(X_validate)\n",
    "\n",
    "print('------- Model 1 -----------')\n",
    "print(classification_report(y_validate, y_pred1))\n",
    "\n",
    "print('------- Model 2 -----------')\n",
    "print(classification_report(y_validate, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc41a75",
   "metadata": {},
   "source": [
    "The second model performs better with max depth of 4 versus max depth of 8 for the first model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5aca2",
   "metadata": {},
   "source": [
    "# Experiment with this model on other datasets with a higher number of output classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6838a1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.52101</th>\n",
       "      <th>13.64</th>\n",
       "      <th>4.49</th>\n",
       "      <th>1.10</th>\n",
       "      <th>71.78</th>\n",
       "      <th>0.06</th>\n",
       "      <th>8.75</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.00.1</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.00.1  1\n",
       "0  1.51761  13.89  3.60  1.36  72.73  0.48  7.83   0.0    0.00  1\n",
       "1  1.51618  13.53  3.55  1.54  72.99  0.39  7.78   0.0    0.00  1\n",
       "2  1.51766  13.21  3.69  1.29  72.61  0.57  8.22   0.0    0.00  1\n",
       "3  1.51742  13.27  3.62  1.24  73.08  0.55  8.07   0.0    0.00  1\n",
       "4  1.51596  12.79  3.61  1.62  72.97  0.64  8.07   0.0    0.26  1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The glass dataset contains 9 columns quantifying the contents of 9 different elements in a glass sample.  \n",
    "# The 10th column is the class of the glass, and integer from 1-7.\n",
    "\n",
    "glass = pd.read_csv('glass.csv')\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8eb6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "glass.columns =['ri', 'na', 'mg', 'al', 'si', 'k','ca','ba','fe', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "658bc1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127, 10), (43, 10), (43, 10))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train, validate, test\n",
    "g_train, g_validate, g_test = prepare.my_split(glass, target='class')\n",
    "g_train.shape, g_validate.shape, g_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ce41d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common value (our baseline) is: 2\n",
      "The rate of occurance (our baseline accuracy) is: 36.22047244094488\n"
     ]
    }
   ],
   "source": [
    "# find the baseline and the baseline accuracy\n",
    "baseline = g_train['class'].value_counts().idxmax()\n",
    "print('The most common value (our baseline) is:', baseline)\n",
    "print('The rate of occurance (our baseline accuracy) is:', len(g_train[g_train['class'] == baseline]) / len(g_train) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80d59687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each of our datasets into X and y \n",
    "\n",
    "X_train = g_train.drop(columns=('class'))\n",
    "y_train = g_train['class']\n",
    "\n",
    "X_validate = g_validate.drop(columns=('class'))\n",
    "y_validate = g_validate['class']\n",
    "\n",
    "X_test = g_test.drop(columns='class')\n",
    "y_test = g_test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e33533f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the models\n",
    "clf1 = DecisionTreeClassifier(max_depth=8)\n",
    "clf2 = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf1.predict(X_train)\n",
    "y_pred2 = clf2.predict(X_train)\n",
    "\n",
    "y_pred_prob1 = clf1.predict_proba(X_train)\n",
    "y_pred_prob2 = clf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd2f5a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 training score: 98.43%\n",
      "Model 2 training score: 77.95%\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "print(f'Model 1 training score: {clf1.score(X_train, y_train):.2%}')\n",
    "print(f'Model 2 training score: {clf2.score(X_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cb706886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Model 1----\n",
      "    0   1  2  3  4   5\n",
      "0  41   0  0  0  0   0\n",
      "1   1  45  0  0  0   0\n",
      "2   1   0  9  0  0   0\n",
      "3   0   0  0  8  0   0\n",
      "4   0   0  0  0  5   0\n",
      "5   0   0  0  0  0  17\n",
      "\n",
      "----Model 2----\n",
      "    0   1  2  3  4   5\n",
      "0  38   1  2  0  0   0\n",
      "1  14  28  2  2  0   0\n",
      "2   3   2  5  0  0   0\n",
      "3   0   0  0  8  0   0\n",
      "4   1   0  0  0  4   0\n",
      "5   0   0  1  0  0  16\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm1 = confusion_matrix(y_train, y_pred1)\n",
    "cm2 = confusion_matrix(y_train, y_pred2)\n",
    "print('----Model 1----')\n",
    "print(pd.DataFrame(cm1))\n",
    "print('')\n",
    "print('----Model 2----')\n",
    "print(pd.DataFrame(cm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edef31eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.95      1.00      0.98        41\n",
      "           2       1.00      0.98      0.99        46\n",
      "           3       1.00      0.90      0.95        10\n",
      "           5       1.00      1.00      1.00         8\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.98       127\n",
      "   macro avg       0.99      0.98      0.99       127\n",
      "weighted avg       0.98      0.98      0.98       127\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.93      0.78        41\n",
      "           2       0.90      0.61      0.73        46\n",
      "           3       0.50      0.50      0.50        10\n",
      "           5       0.80      1.00      0.89         8\n",
      "           6       1.00      0.80      0.89         5\n",
      "           7       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.78       127\n",
      "   macro avg       0.81      0.80      0.79       127\n",
      "weighted avg       0.81      0.78      0.78       127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred1))\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4495e58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.70\n",
      "\n",
      "------- Model 2 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.60\n"
     ]
    }
   ],
   "source": [
    "print('------- Model 1 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf1.score(X_validate, y_validate)))\n",
    "print('')\n",
    "print('------- Model 2 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1fc43881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.93      0.79        14\n",
      "           2       0.83      0.67      0.74        15\n",
      "           3       0.33      0.25      0.29         4\n",
      "           5       0.33      0.50      0.40         2\n",
      "           6       0.50      0.50      0.50         2\n",
      "           7       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.70        43\n",
      "   macro avg       0.61      0.59      0.59        43\n",
      "weighted avg       0.72      0.70      0.69        43\n",
      "\n",
      "------- Model 2 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.93      0.72        14\n",
      "           2       0.71      0.33      0.45        15\n",
      "           3       0.33      0.25      0.29         4\n",
      "           5       0.40      1.00      0.57         2\n",
      "           6       0.50      0.50      0.50         2\n",
      "           7       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.60        43\n",
      "   macro avg       0.59      0.61      0.56        43\n",
      "weighted avg       0.65      0.60      0.58        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification reports\n",
    "y_pred1 = clf1.predict(X_validate)\n",
    "y_pred2 = clf2.predict(X_validate)\n",
    "\n",
    "print('------- Model 1 -----------')\n",
    "print(classification_report(y_validate, y_pred1))\n",
    "\n",
    "print('------- Model 2 -----------')\n",
    "print(classification_report(y_validate, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff0dfe",
   "metadata": {},
   "source": [
    "The first model (max depth 8) performed better on the training set, but the second model (max depth 4)\n",
    "performed better on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3027efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
