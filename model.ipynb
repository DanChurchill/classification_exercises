{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e3bc135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import env\n",
    "import prepare\n",
    "import acquire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb1346",
   "metadata": {},
   "source": [
    "# Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fe56319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 15), (143, 15), (143, 15))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import titanic dataset, run our prepare functions, split into train/validate/test, and validate size of df's\n",
    "df = acquire.get_titanic_data()\n",
    "df = prepare.prep_titanic(df)\n",
    "tit_train, tit_validate, tit_test = prepare.my_split(df, target='survived')\n",
    "tit_train.shape, tit_validate.shape, tit_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35750e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.6958</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   sex   age  sibsp  parch     fare embarked embark_town  \\\n",
       "174         0       1  male  56.0      0      0  30.6958        C   Cherbourg   \n",
       "\n",
       "     alone  sex_female  sex_male  embark_town_Cherbourg  \\\n",
       "174      1           0         1                      1   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  \n",
       "174                       0                        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tit_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5503d37",
   "metadata": {},
   "source": [
    "## What is your baseline prediction?  What is your baseline accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10ae0a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common value (our baseline) is: 0\n",
      "The rate of occurance (our baseline accuracy) is: 59.624413145539904\n"
     ]
    }
   ],
   "source": [
    "# find the most common condition for our target to determine baseline.  It's rate of occurance is the accuracy of \n",
    "# our baseline\n",
    "print('The most common value (our baseline) is:',tit_train.survived.value_counts().idxmax())\n",
    "print('The rate of occurance (our baseline accuracy) is:', len(tit_train[tit_train.survived == 0]) / len(tit_train) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d822e2d",
   "metadata": {},
   "source": [
    "# Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ba85474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each of our datasets into X and y \n",
    "\n",
    "X_train = tit_train.drop(columns=['survived', 'sex', 'embarked', 'embark_town', 'sex_female', 'embark_town_Cherbourg'])\n",
    "y_train = tit_train.survived\n",
    "\n",
    "X_validate = tit_validate.drop(columns=['survived', 'sex', 'embarked', 'embark_town', 'sex_female', 'embark_town_Cherbourg'])\n",
    "y_validate = tit_validate.survived\n",
    "\n",
    "X_test = tit_test.drop(columns=['survived', 'sex', 'embarked', 'embark_town', 'sex_female', 'embark_town_Cherbourg'])\n",
    "y_test = tit_test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b9f54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred_prob = clf.predict_proba(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1943cdc9",
   "metadata": {},
   "source": [
    "## Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bcfe8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 99.30%\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "print(f'training score: {clf.score(X_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc366531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "0  254    0\n",
      "1    3  169\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(pd.DataFrame(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c089ae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       254\n",
      "           1       1.00      0.98      0.99       172\n",
      "\n",
      "    accuracy                           0.99       426\n",
      "   macro avg       0.99      0.99      0.99       426\n",
      "weighted avg       0.99      0.99      0.99       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27929f36",
   "metadata": {},
   "source": [
    "## Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54b11d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Accuracy score is:  0.9929577464788732\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print('------- Model 1 -----------')\n",
    "print('Accuracy score is: ', accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f2929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "True positive rate is: 0.596244131455399\n",
      "False positive rate is 0.0\n",
      "True negative rate is 0.3967136150234742\n",
      "False negative rate is 0.007042253521126761\n"
     ]
    }
   ],
   "source": [
    "# true positive rate, false positive rate, true negative rate, false negative rate\n",
    "tp = cm[0,0]\n",
    "tn = cm[1,1]\n",
    "fp = cm[0,1]\n",
    "fn = cm[1,0]\n",
    "print('------- Model 1 -----------')\n",
    "print('True positive rate is:', tp/(tp+tn+fp+fn))\n",
    "print('False positive rate is', fp/(tp+tn+fp+fn))\n",
    "print('True negative rate is', tn/(tp+tn+fp+fn))\n",
    "print('False negative rate is', fn/(tp+tn+fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3cb3a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Precision is:  1.0\n",
      "Recall is: 0.9825581395348837\n",
      "f1 score is: 0.9912023460410557\n",
      "Support is 0: 254\n",
      "           1: 172\n"
     ]
    }
   ],
   "source": [
    "# precision, recall, f1-score and support\n",
    "print('------- Model 1 -----------')\n",
    "print('Precision is: ', precision_score(y_train, y_pred))\n",
    "print('Recall is:', recall_score(y_train, y_pred))\n",
    "print('f1 score is:', f1_score(y_train, y_pred))\n",
    "print('Support is 0:', tp+fp)\n",
    "print('           1:', tn+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e923d4",
   "metadata": {},
   "source": [
    "## Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37c821c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing max depth to 5\n",
    "clf2 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(X_train)\n",
    "y_pred_prob2 = clf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6930294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "training score for model2: 85.92%\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "print('------- Model 2 -----------')\n",
    "print(f'training score for model2: {clf2.score(X_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa991df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "0  234   20\n",
      "1   40  132\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm2 = confusion_matrix(y_train, y_pred2)\n",
    "print(pd.DataFrame(cm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "145ea84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89       254\n",
      "           1       0.87      0.77      0.81       172\n",
      "\n",
      "    accuracy                           0.86       426\n",
      "   macro avg       0.86      0.84      0.85       426\n",
      "weighted avg       0.86      0.86      0.86       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print('------- Model 2 -----------')\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "921ff35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "Accuracy score for model 2 is:  0.8591549295774648\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print('------- Model 2 -----------')\n",
    "print('Accuracy score for model 2 is: ', accuracy_score(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "870a46aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "True positive rate is: 0.5492957746478874\n",
      "False positive rate is 0.046948356807511735\n",
      "True negative rate is 0.30985915492957744\n",
      "False negative rate is 0.09389671361502347\n"
     ]
    }
   ],
   "source": [
    "# true positive rate, false positive rate, true negative rate, false negative rate\n",
    "tp2 = cm2[0,0]\n",
    "tn2 = cm2[1,1]\n",
    "fp2 = cm2[0,1]\n",
    "fn2 = cm2[1,0]\n",
    "\n",
    "print('------- Model 2 -----------')\n",
    "print('True positive rate is:', tp2/(tp2+tn2+fp2+fn2))\n",
    "print('False positive rate is', fp2/(tp2+tn2+fp2+fn2))\n",
    "print('True negative rate is', tn2/(tp2+tn2+fp2+fn2))\n",
    "print('False negative rate is', fn2/(tp2+tn2+fp2+fn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a18ef222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "Precision is:  0.868421052631579\n",
      "Recall is: 0.7674418604651163\n",
      "f1 score is: 0.8148148148148148\n",
      "Support is 0: 254\n",
      "           1: 172\n"
     ]
    }
   ],
   "source": [
    "# precision, recall, f1-score and support\n",
    "print('------- Model 2 -----------')\n",
    "print('Precision is: ', precision_score(y_train, y_pred2))\n",
    "print('Recall is:', recall_score(y_train, y_pred2))\n",
    "print('f1 score is:', f1_score(y_train, y_pred2))\n",
    "print('Support is 0:', tp2+fp2)\n",
    "print('           1:', tn2+fn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf7ed2d",
   "metadata": {},
   "source": [
    "## Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d493860",
   "metadata": {},
   "source": [
    "Model 1 performs better when evaluating performance against the in-sample (training) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81986450",
   "metadata": {},
   "source": [
    "## Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "078d2d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.77\n",
      "\n",
      "------- Model 2 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.79\n"
     ]
    }
   ],
   "source": [
    "print('------- Model 1 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))\n",
    "print('')\n",
    "print('------- Model 2 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf2.score(X_validate, y_validate)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86d6d55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80        85\n",
      "           1       0.70      0.76      0.73        58\n",
      "\n",
      "    accuracy                           0.77       143\n",
      "   macro avg       0.76      0.77      0.76       143\n",
      "weighted avg       0.77      0.77      0.77       143\n",
      "\n",
      "------- Model 2 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.81      0.82        85\n",
      "           1       0.73      0.76      0.75        58\n",
      "\n",
      "    accuracy                           0.79       143\n",
      "   macro avg       0.78      0.79      0.78       143\n",
      "weighted avg       0.79      0.79      0.79       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "y_pred = clf.predict(X_validate)\n",
    "y_pred2 = clf2.predict(X_validate)\n",
    "\n",
    "print('------- Model 1 -----------')\n",
    "print(classification_report(y_validate, y_pred))\n",
    "\n",
    "print('------- Model 2 -----------')\n",
    "print(classification_report(y_validate, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c615c63",
   "metadata": {},
   "source": [
    "Model 2 performs slightly better with a max depth of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b825aec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
