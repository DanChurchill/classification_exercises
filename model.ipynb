{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92f20247",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import env\n",
    "import prepare\n",
    "import acquire\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ea821",
   "metadata": {},
   "source": [
    "# Titanic Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6331ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 15), (143, 15), (143, 15))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import titanic dataset, run our prepare functions, split into train/validate/test, and validate size of df's\n",
    "df = acquire.get_titanic_data()\n",
    "df = prepare.prep_titanic(df)\n",
    "tit_train, tit_validate, tit_test = prepare.my_split(df, target='survived')\n",
    "tit_train.shape, tit_validate.shape, tit_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "671179d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>164.8667</td>\n",
       "      <td>S</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex   age  sibsp  parch      fare embarked  \\\n",
       "318         1       1  female  31.0      0      2  164.8667        S   \n",
       "\n",
       "     embark_town  alone  sex_female  sex_male  embark_town_Cherbourg  \\\n",
       "318  Southampton      0           1         0                      0   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  \n",
       "318                       0                        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tit_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f643b0c",
   "metadata": {},
   "source": [
    "## What is your baseline prediction?  What is your baseline accuracy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7509f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common value (our baseline) is: 0\n",
      "The rate of occurance (our baseline accuracy) is: 59.624413145539904\n"
     ]
    }
   ],
   "source": [
    "# find the most common condition for our target to determine baseline.  It's rate of occurance is the accuracy of \n",
    "# our baseline\n",
    "print('The most common value (our baseline) is:',tit_train.survived.value_counts().idxmax())\n",
    "print('The rate of occurance (our baseline accuracy) is:', len(tit_train[tit_train.survived == 0]) / len(tit_train) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b6f783",
   "metadata": {},
   "source": [
    "# Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c2b4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each of our datasets into X and y \n",
    "\n",
    "X_train = tit_train.drop(columns=['survived', 'sex', 'embarked', 'embark_town', 'sex_female', 'embark_town_Cherbourg'])\n",
    "y_train = tit_train.survived\n",
    "\n",
    "X_validate = tit_validate.drop(columns=['survived', 'sex', 'embarked', 'embark_town', 'sex_female', 'embark_town_Cherbourg'])\n",
    "y_validate = tit_validate.survived\n",
    "\n",
    "X_test = tit_test.drop(columns=['survived', 'sex', 'embarked', 'embark_town', 'sex_female', 'embark_town_Cherbourg'])\n",
    "y_test = tit_test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6aba0e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the model\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf = clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "y_pred_prob = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d20563f",
   "metadata": {},
   "source": [
    "## Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a449ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 98.59%\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "print(f'training score: {clf.score(X_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5f23356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "0  254    0\n",
      "1    6  166\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(pd.DataFrame(cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5d7d261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       254\n",
      "           1       1.00      0.97      0.98       172\n",
      "\n",
      "    accuracy                           0.99       426\n",
      "   macro avg       0.99      0.98      0.99       426\n",
      "weighted avg       0.99      0.99      0.99       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1c5722",
   "metadata": {},
   "source": [
    "## Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72e38eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Accuracy score is:  0.9859154929577465\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print('------- Model 1 -----------')\n",
    "print('Accuracy score is: ', accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "133ffbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "True positive rate is: 0.596244131455399\n",
      "False positive rate is 0.0\n",
      "True negative rate is 0.38967136150234744\n",
      "False negative rate is 0.014084507042253521\n"
     ]
    }
   ],
   "source": [
    "# true positive rate, false positive rate, true negative rate, false negative rate\n",
    "tp = cm[0,0]\n",
    "tn = cm[1,1]\n",
    "fp = cm[0,1]\n",
    "fn = cm[1,0]\n",
    "print('------- Model 1 -----------')\n",
    "print('True positive rate is:', tp/(tp+tn+fp+fn))\n",
    "print('False positive rate is', fp/(tp+tn+fp+fn))\n",
    "print('True negative rate is', tn/(tp+tn+fp+fn))\n",
    "print('False negative rate is', fn/(tp+tn+fp+fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a887eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Precision is:  1.0\n",
      "Recall is: 0.9651162790697675\n",
      "f1 score is: 0.9822485207100593\n",
      "Support is 0: 254\n",
      "           1: 172\n"
     ]
    }
   ],
   "source": [
    "# precision, recall, f1-score and support\n",
    "print('------- Model 1 -----------')\n",
    "print('Precision is: ', precision_score(y_train, y_pred))\n",
    "print('Recall is:', recall_score(y_train, y_pred))\n",
    "print('f1 score is:', f1_score(y_train, y_pred))\n",
    "print('Support is 0:', tp+fp)\n",
    "print('           1:', tn+fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c2ab4",
   "metadata": {},
   "source": [
    "## Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5a358b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing max depth to 5\n",
    "clf2 = DecisionTreeClassifier(max_depth=5)\n",
    "\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred2 = clf2.predict(X_train)\n",
    "y_pred_prob2 = clf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8f2a59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "training score for model2: 84.74%\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "print('------- Model 2 -----------')\n",
    "print(f'training score for model2: {clf2.score(X_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c341ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1\n",
      "0  248    6\n",
      "1   59  113\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm2 = confusion_matrix(y_train, y_pred2)\n",
    "print(pd.DataFrame(cm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3d53239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.88       254\n",
      "           1       0.95      0.66      0.78       172\n",
      "\n",
      "    accuracy                           0.85       426\n",
      "   macro avg       0.88      0.82      0.83       426\n",
      "weighted avg       0.87      0.85      0.84       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print('------- Model 2 -----------')\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad8c4345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "Accuracy score for model 2 is:  0.8474178403755869\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "print('------- Model 2 -----------')\n",
    "print('Accuracy score for model 2 is: ', accuracy_score(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0cc2f30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "True positive rate is: 0.5821596244131455\n",
      "False positive rate is 0.014084507042253521\n",
      "True negative rate is 0.2652582159624413\n",
      "False negative rate is 0.13849765258215962\n"
     ]
    }
   ],
   "source": [
    "# true positive rate, false positive rate, true negative rate, false negative rate\n",
    "tp2 = cm2[0,0]\n",
    "tn2 = cm2[1,1]\n",
    "fp2 = cm2[0,1]\n",
    "fn2 = cm2[1,0]\n",
    "\n",
    "print('------- Model 2 -----------')\n",
    "print('True positive rate is:', tp2/(tp2+tn2+fp2+fn2))\n",
    "print('False positive rate is', fp2/(tp2+tn2+fp2+fn2))\n",
    "print('True negative rate is', tn2/(tp2+tn2+fp2+fn2))\n",
    "print('False negative rate is', fn2/(tp2+tn2+fp2+fn2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3edb47b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 2 -----------\n",
      "Precision is:  0.9495798319327731\n",
      "Recall is: 0.6569767441860465\n",
      "f1 score is: 0.7766323024054982\n",
      "Support is 0: 254\n",
      "           1: 172\n"
     ]
    }
   ],
   "source": [
    "# precision, recall, f1-score and support\n",
    "print('------- Model 2 -----------')\n",
    "print('Precision is: ', precision_score(y_train, y_pred2))\n",
    "print('Recall is:', recall_score(y_train, y_pred2))\n",
    "print('f1 score is:', f1_score(y_train, y_pred2))\n",
    "print('Support is 0:', tp2+fp2)\n",
    "print('           1:', tn2+fn2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec18a469",
   "metadata": {},
   "source": [
    "## Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5144c74",
   "metadata": {},
   "source": [
    "Model 1 performs better when evaluating performance against the in-sample (training) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b083be97",
   "metadata": {},
   "source": [
    "## Which model performs best on your out-of-sample data, the validate set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7348db8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.73\n",
      "\n",
      "------- Model 2 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.73\n"
     ]
    }
   ],
   "source": [
    "print('------- Model 1 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf.score(X_validate, y_validate)))\n",
    "print('')\n",
    "print('------- Model 2 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf2.score(X_validate, y_validate)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fdda672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78        85\n",
      "           1       0.67      0.67      0.67        58\n",
      "\n",
      "    accuracy                           0.73       143\n",
      "   macro avg       0.72      0.72      0.72       143\n",
      "weighted avg       0.73      0.73      0.73       143\n",
      "\n",
      "------- Model 2 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.75      0.77        85\n",
      "           1       0.66      0.71      0.68        58\n",
      "\n",
      "    accuracy                           0.73       143\n",
      "   macro avg       0.73      0.73      0.73       143\n",
      "weighted avg       0.74      0.73      0.74       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "y_pred = clf.predict(X_validate)\n",
    "y_pred2 = clf2.predict(X_validate)\n",
    "\n",
    "print('------- Model 1 -----------')\n",
    "print(classification_report(y_validate, y_pred))\n",
    "\n",
    "print('------- Model 2 -----------')\n",
    "print(classification_report(y_validate, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715fa07e",
   "metadata": {},
   "source": [
    "Model 2 performs slightly better with a max depth of 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd126bc",
   "metadata": {},
   "source": [
    "# Work through these same exercises using the iris dataset.\n",
    "    ## building two models simultaneously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e93865fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 5), (30, 5), (30, 5))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get and prepare iris data\n",
    "iris = acquire.get_iris_data()\n",
    "iris = prepare.prep_iris(iris)\n",
    "i_train, i_validate, i_test = prepare.my_split(iris, target='species')\n",
    "i_train.shape, i_validate.shape, i_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "62f40bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common value (our baseline) is: versicolor\n",
      "The rate of occurance (our baseline accuracy) is: 33.33333333333333\n"
     ]
    }
   ],
   "source": [
    "# find the baseline and the baseline accuracy\n",
    "baseline = i_train.species.value_counts().idxmax()\n",
    "print('The most common value (our baseline) is:', baseline)\n",
    "print('The rate of occurance (our baseline accuracy) is:', len(i_train[i_train.species == baseline]) / len(i_train) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4dc9a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each of our datasets into X and y \n",
    "\n",
    "X_train = i_train.drop(columns=('species'))\n",
    "y_train = i_train.species\n",
    "\n",
    "X_validate = i_validate.drop(columns=('species'))\n",
    "y_validate = i_validate.species\n",
    "\n",
    "X_test = i_test.drop(columns='species')\n",
    "y_test = i_test.species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1e85026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the models\n",
    "clf1 = DecisionTreeClassifier(max_depth=8)\n",
    "clf2 = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf1.predict(X_train)\n",
    "y_pred2 = clf2.predict(X_train)\n",
    "\n",
    "y_pred_prob1 = clf1.predict_proba(X_train)\n",
    "y_pred_prob2 = clf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "82afab96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 training score: 100.00%\n",
      "Model 2 training score: 97.78%\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "print(f'Model 1 training score: {clf1.score(X_train, y_train):.2%}')\n",
    "print(f'Model 2 training score: {clf2.score(X_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "31c4da7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Model 1----\n",
      "    0   1   2\n",
      "0  30   0   0\n",
      "1   0  30   0\n",
      "2   0   0  30\n",
      "\n",
      "----Model 2----\n",
      "    0   1   2\n",
      "0  30   0   0\n",
      "1   0  28   2\n",
      "2   0   0  30\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm1 = confusion_matrix(y_train, y_pred1)\n",
    "cm2 = confusion_matrix(y_train, y_pred2)\n",
    "print('----Model 1----')\n",
    "print(pd.DataFrame(cm1))\n",
    "print('')\n",
    "print('----Model 2----')\n",
    "print(pd.DataFrame(cm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3325df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        30\n",
      "  versicolor       1.00      1.00      1.00        30\n",
      "   virginica       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00        90\n",
      "   macro avg       1.00      1.00      1.00        90\n",
      "weighted avg       1.00      1.00      1.00        90\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        30\n",
      "  versicolor       1.00      0.93      0.97        30\n",
      "   virginica       0.94      1.00      0.97        30\n",
      "\n",
      "    accuracy                           0.98        90\n",
      "   macro avg       0.98      0.98      0.98        90\n",
      "weighted avg       0.98      0.98      0.98        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred1))\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031c6a07",
   "metadata": {},
   "source": [
    "## ...and comparing with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2c6462da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.93\n",
      "\n",
      "------- Model 2 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.90\n"
     ]
    }
   ],
   "source": [
    "print('------- Model 1 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf1.score(X_validate, y_validate)))\n",
    "print('')\n",
    "print('------- Model 2 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8173100c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.80      0.89        10\n",
      "   virginica       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        30\n",
      "   macro avg       0.94      0.93      0.93        30\n",
      "weighted avg       0.94      0.93      0.93        30\n",
      "\n",
      "------- Model 2 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        10\n",
      "  versicolor       1.00      0.70      0.82        10\n",
      "   virginica       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.90        30\n",
      "   macro avg       0.92      0.90      0.90        30\n",
      "weighted avg       0.92      0.90      0.90        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "y_pred1 = clf1.predict(X_validate)\n",
    "y_pred2 = clf2.predict(X_validate)\n",
    "\n",
    "print('------- Model 1 -----------')\n",
    "print(classification_report(y_validate, y_pred1))\n",
    "\n",
    "print('------- Model 2 -----------')\n",
    "print(classification_report(y_validate, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc41a75",
   "metadata": {},
   "source": [
    "The first model performs better with max depth of 8 versus max depth of 2 for the second model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5aca2",
   "metadata": {},
   "source": [
    "# Experiment with this model on other datasets with a higher number of output classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6838a1b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.52101</th>\n",
       "      <th>13.64</th>\n",
       "      <th>4.49</th>\n",
       "      <th>1.10</th>\n",
       "      <th>71.78</th>\n",
       "      <th>0.06</th>\n",
       "      <th>8.75</th>\n",
       "      <th>0.00</th>\n",
       "      <th>0.00.1</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51596</td>\n",
       "      <td>12.79</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.62</td>\n",
       "      <td>72.97</td>\n",
       "      <td>0.64</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.00.1  1\n",
       "0  1.51761  13.89  3.60  1.36  72.73  0.48  7.83   0.0    0.00  1\n",
       "1  1.51618  13.53  3.55  1.54  72.99  0.39  7.78   0.0    0.00  1\n",
       "2  1.51766  13.21  3.69  1.29  72.61  0.57  8.22   0.0    0.00  1\n",
       "3  1.51742  13.27  3.62  1.24  73.08  0.55  8.07   0.0    0.00  1\n",
       "4  1.51596  12.79  3.61  1.62  72.97  0.64  8.07   0.0    0.26  1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The glass dataset contains 9 columns quantifying the contents of 9 different elements in a glass sample.  \n",
    "# The 10th column is the class of the glass, and integer from 1-7.\n",
    "\n",
    "glass = pd.read_csv('glass.csv')\n",
    "glass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c8eb6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "glass.columns =['ri', 'na', 'mg', 'al', 'si', 'k','ca','ba','fe', 'class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "658bc1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127, 10), (43, 10), (43, 10))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split into train, validate, test\n",
    "g_train, g_validate, g_test = prepare.my_split(glass, target='class')\n",
    "g_train.shape, g_validate.shape, g_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6ce41d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common value (our baseline) is: 2\n",
      "The rate of occurance (our baseline accuracy) is: 36.22047244094488\n"
     ]
    }
   ],
   "source": [
    "# find the baseline and the baseline accuracy\n",
    "baseline = g_train['class'].value_counts().idxmax()\n",
    "print('The most common value (our baseline) is:', baseline)\n",
    "print('The rate of occurance (our baseline accuracy) is:', len(g_train[g_train['class'] == baseline]) / len(g_train) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80d59687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split each of our datasets into X and y \n",
    "\n",
    "X_train = g_train.drop(columns=('class'))\n",
    "y_train = g_train['class']\n",
    "\n",
    "X_validate = g_validate.drop(columns=('class'))\n",
    "y_validate = g_validate['class']\n",
    "\n",
    "X_test = g_test.drop(columns='class')\n",
    "y_test = g_test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e33533f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the models\n",
    "clf1 = DecisionTreeClassifier(max_depth=8)\n",
    "clf2 = DecisionTreeClassifier(max_depth=4)\n",
    "\n",
    "clf1 = clf1.fit(X_train, y_train)\n",
    "clf2 = clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred1 = clf1.predict(X_train)\n",
    "y_pred2 = clf2.predict(X_train)\n",
    "\n",
    "y_pred_prob1 = clf1.predict_proba(X_train)\n",
    "y_pred_prob2 = clf2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd2f5a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 training score: 96.06%\n",
      "Model 2 training score: 78.74%\n"
     ]
    }
   ],
   "source": [
    "# model score\n",
    "print(f'Model 1 training score: {clf1.score(X_train, y_train):.2%}')\n",
    "print(f'Model 2 training score: {clf2.score(X_train, y_train):.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb706886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Model 1----\n",
      "    0   1  2  3  4   5\n",
      "0  41   0  0  0  0   0\n",
      "1   3  43  0  0  0   0\n",
      "2   2   0  8  0  0   0\n",
      "3   0   0  0  8  0   0\n",
      "4   0   0  0  0  5   0\n",
      "5   0   0  0  0  0  17\n",
      "\n",
      "----Model 2----\n",
      "    0   1  2  3  4   5\n",
      "0  37   3  1  0  0   0\n",
      "1  10  30  3  3  0   0\n",
      "2   5   0  5  0  0   0\n",
      "3   0   0  0  8  0   0\n",
      "4   1   0  0  0  4   0\n",
      "5   0   0  1  0  0  16\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "cm1 = confusion_matrix(y_train, y_pred1)\n",
    "cm2 = confusion_matrix(y_train, y_pred2)\n",
    "print('----Model 1----')\n",
    "print(pd.DataFrame(cm1))\n",
    "print('')\n",
    "print('----Model 2----')\n",
    "print(pd.DataFrame(cm2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edef31eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      1.00      0.94        41\n",
      "           2       1.00      0.93      0.97        46\n",
      "           3       1.00      0.80      0.89        10\n",
      "           5       1.00      1.00      1.00         8\n",
      "           6       1.00      1.00      1.00         5\n",
      "           7       1.00      1.00      1.00        17\n",
      "\n",
      "    accuracy                           0.96       127\n",
      "   macro avg       0.98      0.96      0.97       127\n",
      "weighted avg       0.96      0.96      0.96       127\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.90      0.79        41\n",
      "           2       0.91      0.65      0.76        46\n",
      "           3       0.50      0.50      0.50        10\n",
      "           5       0.73      1.00      0.84         8\n",
      "           6       1.00      0.80      0.89         5\n",
      "           7       1.00      0.94      0.97        17\n",
      "\n",
      "    accuracy                           0.79       127\n",
      "   macro avg       0.81      0.80      0.79       127\n",
      "weighted avg       0.81      0.79      0.79       127\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred1))\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4495e58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.74\n",
      "\n",
      "------- Model 2 -----------\n",
      "Accuracy of Decision Tree classifier on validate set: 0.70\n"
     ]
    }
   ],
   "source": [
    "print('------- Model 1 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf1.score(X_validate, y_validate)))\n",
    "print('')\n",
    "print('------- Model 2 -----------')\n",
    "print('Accuracy of Decision Tree classifier on validate set: {:.2f}'\n",
    "     .format(clf2.score(X_validate, y_validate)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1fc43881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- Model 1 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.86      0.83        14\n",
      "           2       0.74      0.93      0.82        15\n",
      "           3       0.00      0.00      0.00         4\n",
      "           5       1.00      1.00      1.00         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.74        43\n",
      "   macro avg       0.56      0.58      0.56        43\n",
      "weighted avg       0.68      0.74      0.70        43\n",
      "\n",
      "------- Model 2 -----------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.79      0.76        14\n",
      "           2       0.72      0.87      0.79        15\n",
      "           3       0.00      0.00      0.00         4\n",
      "           5       0.67      1.00      0.80         2\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.70        43\n",
      "   macro avg       0.52      0.55      0.52        43\n",
      "weighted avg       0.66      0.70      0.67        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification reports\n",
    "y_pred1 = clf1.predict(X_validate)\n",
    "y_pred2 = clf2.predict(X_validate)\n",
    "\n",
    "print('------- Model 1 -----------')\n",
    "print(classification_report(y_validate, y_pred1))\n",
    "\n",
    "print('------- Model 2 -----------')\n",
    "print(classification_report(y_validate, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceff0dfe",
   "metadata": {},
   "source": [
    "The first model (max depth 8) performed better on the training set, but the second model (max depth 4)\n",
    "performed better on the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8ac84e",
   "metadata": {},
   "source": [
    "# Random Forest Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe524d4c",
   "metadata": {},
   "source": [
    "### Continue working in your model file with titanic data to do the following:\n",
    "\n",
    "Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40cefba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72b6905a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 15), (143, 15), (143, 15))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df = prepare.prep_titanic(df)\n",
    "train, validate, test = prepare.my_split(df, target='survived')\n",
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ece65a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Cherbourg</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>32.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19.2583</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>22.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>18.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>29.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex    age  sibsp  parch     fare embarked  \\\n",
       "543         1       2    male  32.00      1      0  26.0000        S   \n",
       "469         1       3  female   0.75      2      1  19.2583        C   \n",
       "323         1       2  female  22.00      1      1  29.0000        S   \n",
       "228         0       2    male  18.00      0      0  13.0000        S   \n",
       "510         1       3    male  29.00      0      0   7.7500        Q   \n",
       "\n",
       "     embark_town  alone  sex_female  sex_male  embark_town_Cherbourg  \\\n",
       "543  Southampton      0           0         1                      0   \n",
       "469    Cherbourg      0           1         0                      1   \n",
       "323  Southampton      0           1         0                      0   \n",
       "228  Southampton      1           0         1                      0   \n",
       "510   Queenstown      1           0         1                      0   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  \n",
       "543                       0                        1  \n",
       "469                       0                        0  \n",
       "323                       0                        1  \n",
       "228                       0                        1  \n",
       "510                       1                        0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c118aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# id columns for features in the model\n",
    "features = ['pclass', 'age','alone','fare','sex_male']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cd4c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y versions of our train/validate/test datasets\n",
    "X_train = train[features]\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate[features]\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test[features]\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f807eaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random forest\n",
    "rf = RandomForestClassifier(min_samples_leaf=1,\n",
    "                            max_depth=10, \n",
    "                            random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4742e356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train random forest model\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f390e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "y_pred = rf.predict(X_train)\n",
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974e14c",
   "metadata": {},
   "source": [
    "### Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe600049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.96\n"
     ]
    }
   ],
   "source": [
    "# check accuracy\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78e79d6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[254   0]\n",
      " [ 15 157]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dda8a312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       254\n",
      "           1       1.00      0.91      0.95       172\n",
      "\n",
      "    accuracy                           0.96       426\n",
      "   macro avg       0.97      0.96      0.96       426\n",
      "weighted avg       0.97      0.96      0.96       426\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f426cc15",
   "metadata": {},
   "source": [
    "### Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8012d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "# create function to output requested scoring of model\n",
    "\n",
    "def model_scores(cm, min_leaf, max_depth):\n",
    "    '''\n",
    "    Function to get all model scores necessary for codeup exercises\n",
    "    Accepts a confusion matrix, and prints a report with the following:\n",
    "        Accuracy\n",
    "        True positive rate\n",
    "        False positive rate\n",
    "        True negative rate\n",
    "        False negative rate \n",
    "        Precision\n",
    "        Recall\n",
    "        f1-score\n",
    "        positive support\n",
    "        negative support\n",
    "    '''\n",
    "    \n",
    "    TN = cm[0,0]\n",
    "    FP = cm[0,1]\n",
    "    FN = cm[1,0]\n",
    "    TP = cm[1,1]\n",
    "    ALL = TP + FP + FN + TN\n",
    "    \n",
    "    print('Model stats for Random Forest with:')\n",
    "    print(\"\")\n",
    "    print('     min_samples_leaf =',min_leaf)\n",
    "    print('        and max_depth =',max_depth)\n",
    "    print(\"\")\n",
    "\n",
    "    # accuracy\n",
    "    acc = (TP + TN) / ALL\n",
    "    print('Accuracy: {:.2f}'.format(acc))\n",
    "#     # true positive rate, also recall\n",
    "#     TPR = recall = TP/ (TP + FN)\n",
    "#     print('True Positive Rate: {:.2f}'.format(TPR))\n",
    "#     # false positive rate\n",
    "#     FPR = FP / (FP + TN)\n",
    "#     print('False Positive Rate: {:.2f}'.format(FPR))\n",
    "#     # true negative rate\n",
    "#     TNR = TN / (TN + FP)\n",
    "#     print('True Negative Rate: {:.2f}'.format(TNR))\n",
    "#     # false negative rate\n",
    "#     FNR = FN / (FN + TP)\n",
    "#     print('Flase Negative Rate: {:.2f}'.format(FNR))\n",
    "#     # precision\n",
    "#     precision = TP / (TP + FP)\n",
    "#     print('Precision: {:.2f}'.format(precision))\n",
    "#     # recall\n",
    "#     print('Recall: {:.2f}'.format(recall))\n",
    "#     # f1\n",
    "#     f1_score = 2 * (precision*recall) / (precision+recall)\n",
    "#     print('f1 score: {:.2f}'.format(f1_score))\n",
    "#     # support\n",
    "#     support_pos = TP + FN\n",
    "#     print('Positive support:',support_pos)\n",
    "#     support_neg = FP + TN\n",
    "#     print('Negative support:',support_neg)\n",
    "#     print('-----------------------------------------')\n",
    "    \n",
    "model_scores(cm, 1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3c995",
   "metadata": {},
   "source": [
    "## Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "69780368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.78\n",
      "True Positive Rate: 0.49\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.51\n",
      "Precision: 0.93\n",
      "Recall: 0.49\n",
      "f1 score: 0.65\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.79\n",
      "True Positive Rate: 0.52\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.48\n",
      "Precision: 0.94\n",
      "Recall: 0.52\n",
      "f1 score: 0.67\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.64\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.36\n",
      "Precision: 0.92\n",
      "Recall: 0.64\n",
      "f1 score: 0.76\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.84\n",
      "True Positive Rate: 0.69\n",
      "False Positive Rate: 0.05\n",
      "True Negative Rate: 0.95\n",
      "Flase Negative Rate: 0.31\n",
      "Precision: 0.90\n",
      "Recall: 0.69\n",
      "f1 score: 0.78\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.73\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.27\n",
      "Precision: 0.92\n",
      "Recall: 0.73\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.90\n",
      "True Positive Rate: 0.81\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.19\n",
      "Precision: 0.94\n",
      "Recall: 0.81\n",
      "f1 score: 0.87\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.93\n",
      "True Positive Rate: 0.85\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.15\n",
      "Precision: 0.97\n",
      "Recall: 0.85\n",
      "f1 score: 0.91\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.95\n",
      "True Positive Rate: 0.88\n",
      "False Positive Rate: 0.01\n",
      "True Negative Rate: 0.99\n",
      "Flase Negative Rate: 0.12\n",
      "Precision: 0.99\n",
      "Recall: 0.88\n",
      "f1 score: 0.93\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.95\n",
      "True Positive Rate: 0.88\n",
      "False Positive Rate: 0.00\n",
      "True Negative Rate: 1.00\n",
      "Flase Negative Rate: 0.12\n",
      "Precision: 1.00\n",
      "Recall: 0.88\n",
      "f1 score: 0.94\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.96\n",
      "True Positive Rate: 0.91\n",
      "False Positive Rate: 0.00\n",
      "True Negative Rate: 1.00\n",
      "Flase Negative Rate: 0.09\n",
      "Precision: 1.00\n",
      "Recall: 0.91\n",
      "f1 score: 0.95\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.78\n",
      "True Positive Rate: 0.49\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.51\n",
      "Precision: 0.93\n",
      "Recall: 0.49\n",
      "f1 score: 0.65\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.79\n",
      "True Positive Rate: 0.52\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.48\n",
      "Precision: 0.94\n",
      "Recall: 0.52\n",
      "f1 score: 0.67\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.84\n",
      "True Positive Rate: 0.65\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.35\n",
      "Precision: 0.92\n",
      "Recall: 0.65\n",
      "f1 score: 0.76\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.84\n",
      "True Positive Rate: 0.69\n",
      "False Positive Rate: 0.05\n",
      "True Negative Rate: 0.95\n",
      "Flase Negative Rate: 0.31\n",
      "Precision: 0.90\n",
      "Recall: 0.69\n",
      "f1 score: 0.78\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.74\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.26\n",
      "Precision: 0.90\n",
      "Recall: 0.74\n",
      "f1 score: 0.82\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.88\n",
      "True Positive Rate: 0.81\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.19\n",
      "Precision: 0.89\n",
      "Recall: 0.81\n",
      "f1 score: 0.85\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.89\n",
      "True Positive Rate: 0.81\n",
      "False Positive Rate: 0.05\n",
      "True Negative Rate: 0.95\n",
      "Flase Negative Rate: 0.19\n",
      "Precision: 0.92\n",
      "Recall: 0.81\n",
      "f1 score: 0.86\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.90\n",
      "True Positive Rate: 0.82\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.18\n",
      "Precision: 0.93\n",
      "Recall: 0.82\n",
      "f1 score: 0.87\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.91\n",
      "True Positive Rate: 0.83\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.17\n",
      "Precision: 0.93\n",
      "Recall: 0.83\n",
      "f1 score: 0.88\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.92\n",
      "True Positive Rate: 0.86\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.14\n",
      "Precision: 0.94\n",
      "Recall: 0.86\n",
      "f1 score: 0.90\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.78\n",
      "True Positive Rate: 0.49\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.51\n",
      "Precision: 0.93\n",
      "Recall: 0.49\n",
      "f1 score: 0.65\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.79\n",
      "True Positive Rate: 0.52\n",
      "False Positive Rate: 0.03\n",
      "True Negative Rate: 0.97\n",
      "Flase Negative Rate: 0.48\n",
      "Precision: 0.93\n",
      "Recall: 0.52\n",
      "f1 score: 0.67\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.64\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.36\n",
      "Precision: 0.91\n",
      "Recall: 0.64\n",
      "f1 score: 0.75\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.84\n",
      "True Positive Rate: 0.69\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.31\n",
      "Precision: 0.89\n",
      "Recall: 0.69\n",
      "f1 score: 0.78\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.74\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.26\n",
      "Precision: 0.90\n",
      "Recall: 0.74\n",
      "f1 score: 0.82\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.88\n",
      "True Positive Rate: 0.78\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.22\n",
      "Precision: 0.89\n",
      "Recall: 0.78\n",
      "f1 score: 0.84\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.88\n",
      "True Positive Rate: 0.79\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.21\n",
      "Precision: 0.90\n",
      "Recall: 0.79\n",
      "f1 score: 0.84\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.88\n",
      "True Positive Rate: 0.78\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.22\n",
      "Precision: 0.90\n",
      "Recall: 0.78\n",
      "f1 score: 0.84\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.88\n",
      "True Positive Rate: 0.79\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.21\n",
      "Precision: 0.91\n",
      "Recall: 0.79\n",
      "f1 score: 0.84\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.88\n",
      "True Positive Rate: 0.79\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.21\n",
      "Precision: 0.90\n",
      "Recall: 0.79\n",
      "f1 score: 0.84\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.78\n",
      "True Positive Rate: 0.49\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.51\n",
      "Precision: 0.93\n",
      "Recall: 0.49\n",
      "f1 score: 0.65\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.79\n",
      "True Positive Rate: 0.52\n",
      "False Positive Rate: 0.03\n",
      "True Negative Rate: 0.97\n",
      "Flase Negative Rate: 0.48\n",
      "Precision: 0.93\n",
      "Recall: 0.52\n",
      "f1 score: 0.67\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.64\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.36\n",
      "Precision: 0.92\n",
      "Recall: 0.64\n",
      "f1 score: 0.76\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.84\n",
      "True Positive Rate: 0.69\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.31\n",
      "Precision: 0.89\n",
      "Recall: 0.69\n",
      "f1 score: 0.78\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.75\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.25\n",
      "Precision: 0.88\n",
      "Recall: 0.75\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.77\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.23\n",
      "Precision: 0.88\n",
      "Recall: 0.77\n",
      "f1 score: 0.82\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.87\n",
      "True Positive Rate: 0.77\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.23\n",
      "Precision: 0.89\n",
      "Recall: 0.77\n",
      "f1 score: 0.83\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.87\n",
      "True Positive Rate: 0.78\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.22\n",
      "Precision: 0.88\n",
      "Recall: 0.78\n",
      "f1 score: 0.83\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.88\n",
      "True Positive Rate: 0.78\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.22\n",
      "Precision: 0.90\n",
      "Recall: 0.78\n",
      "f1 score: 0.83\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.87\n",
      "True Positive Rate: 0.78\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.22\n",
      "Precision: 0.89\n",
      "Recall: 0.78\n",
      "f1 score: 0.83\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.78\n",
      "True Positive Rate: 0.49\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.51\n",
      "Precision: 0.93\n",
      "Recall: 0.49\n",
      "f1 score: 0.65\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.79\n",
      "True Positive Rate: 0.53\n",
      "False Positive Rate: 0.03\n",
      "True Negative Rate: 0.97\n",
      "Flase Negative Rate: 0.47\n",
      "Precision: 0.93\n",
      "Recall: 0.53\n",
      "f1 score: 0.67\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.62\n",
      "False Positive Rate: 0.03\n",
      "True Negative Rate: 0.97\n",
      "Flase Negative Rate: 0.38\n",
      "Precision: 0.93\n",
      "Recall: 0.62\n",
      "f1 score: 0.75\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.65\n",
      "False Positive Rate: 0.05\n",
      "True Negative Rate: 0.95\n",
      "Flase Negative Rate: 0.35\n",
      "Precision: 0.90\n",
      "Recall: 0.65\n",
      "f1 score: 0.75\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.74\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.26\n",
      "Precision: 0.89\n",
      "Recall: 0.74\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.87\n",
      "True Positive Rate: 0.76\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.24\n",
      "Precision: 0.90\n",
      "Recall: 0.76\n",
      "f1 score: 0.82\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.87\n",
      "True Positive Rate: 0.77\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.23\n",
      "Precision: 0.89\n",
      "Recall: 0.77\n",
      "f1 score: 0.82\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.87\n",
      "True Positive Rate: 0.76\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.24\n",
      "Precision: 0.89\n",
      "Recall: 0.76\n",
      "f1 score: 0.82\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.87\n",
      "True Positive Rate: 0.77\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.23\n",
      "Precision: 0.89\n",
      "Recall: 0.77\n",
      "f1 score: 0.83\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.87\n",
      "True Positive Rate: 0.77\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.23\n",
      "Precision: 0.89\n",
      "Recall: 0.77\n",
      "f1 score: 0.83\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.78\n",
      "True Positive Rate: 0.49\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.51\n",
      "Precision: 0.93\n",
      "Recall: 0.49\n",
      "f1 score: 0.65\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.79\n",
      "True Positive Rate: 0.53\n",
      "False Positive Rate: 0.03\n",
      "True Negative Rate: 0.97\n",
      "Flase Negative Rate: 0.47\n",
      "Precision: 0.93\n",
      "Recall: 0.53\n",
      "f1 score: 0.67\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.63\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.37\n",
      "Precision: 0.92\n",
      "Recall: 0.63\n",
      "f1 score: 0.75\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.66\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.34\n",
      "Precision: 0.88\n",
      "Recall: 0.66\n",
      "f1 score: 0.75\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.72\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.28\n",
      "Precision: 0.87\n",
      "Recall: 0.72\n",
      "f1 score: 0.79\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.75\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.25\n",
      "Precision: 0.88\n",
      "Recall: 0.75\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.76\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.24\n",
      "Precision: 0.88\n",
      "Recall: 0.76\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.73\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.27\n",
      "Precision: 0.88\n",
      "Recall: 0.73\n",
      "f1 score: 0.80\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.75\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.25\n",
      "Precision: 0.88\n",
      "Recall: 0.75\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.75\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.25\n",
      "Precision: 0.88\n",
      "Recall: 0.75\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.78\n",
      "True Positive Rate: 0.49\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.51\n",
      "Precision: 0.93\n",
      "Recall: 0.49\n",
      "f1 score: 0.65\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.79\n",
      "True Positive Rate: 0.53\n",
      "False Positive Rate: 0.03\n",
      "True Negative Rate: 0.97\n",
      "Flase Negative Rate: 0.47\n",
      "Precision: 0.93\n",
      "Recall: 0.53\n",
      "f1 score: 0.67\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.81\n",
      "True Positive Rate: 0.60\n",
      "False Positive Rate: 0.05\n",
      "True Negative Rate: 0.95\n",
      "Flase Negative Rate: 0.40\n",
      "Precision: 0.90\n",
      "Recall: 0.60\n",
      "f1 score: 0.72\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.82\n",
      "True Positive Rate: 0.65\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.35\n",
      "Precision: 0.88\n",
      "Recall: 0.65\n",
      "f1 score: 0.74\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.73\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.27\n",
      "Precision: 0.88\n",
      "Recall: 0.73\n",
      "f1 score: 0.80\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.73\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.27\n",
      "Precision: 0.88\n",
      "Recall: 0.73\n",
      "f1 score: 0.80\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.75\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.25\n",
      "Precision: 0.89\n",
      "Recall: 0.75\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.74\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.26\n",
      "Precision: 0.88\n",
      "Recall: 0.74\n",
      "f1 score: 0.80\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.74\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.26\n",
      "Precision: 0.88\n",
      "Recall: 0.74\n",
      "f1 score: 0.80\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.86\n",
      "True Positive Rate: 0.74\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.26\n",
      "Precision: 0.88\n",
      "Recall: 0.74\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.78\n",
      "True Positive Rate: 0.49\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.51\n",
      "Precision: 0.93\n",
      "Recall: 0.49\n",
      "f1 score: 0.65\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.80\n",
      "True Positive Rate: 0.55\n",
      "False Positive Rate: 0.03\n",
      "True Negative Rate: 0.97\n",
      "Flase Negative Rate: 0.45\n",
      "Precision: 0.92\n",
      "Recall: 0.55\n",
      "f1 score: 0.69\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.81\n",
      "True Positive Rate: 0.60\n",
      "False Positive Rate: 0.05\n",
      "True Negative Rate: 0.95\n",
      "Flase Negative Rate: 0.40\n",
      "Precision: 0.89\n",
      "Recall: 0.60\n",
      "f1 score: 0.72\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.82\n",
      "True Positive Rate: 0.64\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.36\n",
      "Precision: 0.88\n",
      "Recall: 0.64\n",
      "f1 score: 0.74\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.70\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.30\n",
      "Precision: 0.86\n",
      "Recall: 0.70\n",
      "f1 score: 0.77\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.74\n",
      "False Positive Rate: 0.08\n",
      "True Negative Rate: 0.92\n",
      "Flase Negative Rate: 0.26\n",
      "Precision: 0.86\n",
      "Recall: 0.74\n",
      "f1 score: 0.80\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.73\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.27\n",
      "Precision: 0.88\n",
      "Recall: 0.73\n",
      "f1 score: 0.80\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.74\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.26\n",
      "Precision: 0.88\n",
      "Recall: 0.74\n",
      "f1 score: 0.80\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.74\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.26\n",
      "Precision: 0.88\n",
      "Recall: 0.74\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.74\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.26\n",
      "Precision: 0.88\n",
      "Recall: 0.74\n",
      "f1 score: 0.81\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.78\n",
      "True Positive Rate: 0.49\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.51\n",
      "Precision: 0.93\n",
      "Recall: 0.49\n",
      "f1 score: 0.65\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.80\n",
      "True Positive Rate: 0.55\n",
      "False Positive Rate: 0.03\n",
      "True Negative Rate: 0.97\n",
      "Flase Negative Rate: 0.45\n",
      "Precision: 0.92\n",
      "Recall: 0.55\n",
      "f1 score: 0.69\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.81\n",
      "True Positive Rate: 0.60\n",
      "False Positive Rate: 0.04\n",
      "True Negative Rate: 0.96\n",
      "Flase Negative Rate: 0.40\n",
      "Precision: 0.90\n",
      "Recall: 0.60\n",
      "f1 score: 0.72\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.82\n",
      "True Positive Rate: 0.64\n",
      "False Positive Rate: 0.06\n",
      "True Negative Rate: 0.94\n",
      "Flase Negative Rate: 0.36\n",
      "Precision: 0.87\n",
      "Recall: 0.64\n",
      "f1 score: 0.74\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.68\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.32\n",
      "Precision: 0.86\n",
      "Recall: 0.68\n",
      "f1 score: 0.76\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.84\n",
      "True Positive Rate: 0.72\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.28\n",
      "Precision: 0.87\n",
      "Recall: 0.72\n",
      "f1 score: 0.78\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.84\n",
      "True Positive Rate: 0.72\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.28\n",
      "Precision: 0.87\n",
      "Recall: 0.72\n",
      "f1 score: 0.79\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.73\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.27\n",
      "Precision: 0.88\n",
      "Recall: 0.73\n",
      "f1 score: 0.80\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.73\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.27\n",
      "Precision: 0.87\n",
      "Recall: 0.73\n",
      "f1 score: 0.79\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.85\n",
      "True Positive Rate: 0.73\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.27\n",
      "Precision: 0.87\n",
      "Recall: 0.73\n",
      "f1 score: 0.79\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.78\n",
      "True Positive Rate: 0.49\n",
      "False Positive Rate: 0.02\n",
      "True Negative Rate: 0.98\n",
      "Flase Negative Rate: 0.51\n",
      "Precision: 0.93\n",
      "Recall: 0.49\n",
      "f1 score: 0.65\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.80\n",
      "True Positive Rate: 0.55\n",
      "False Positive Rate: 0.03\n",
      "True Negative Rate: 0.97\n",
      "Flase Negative Rate: 0.45\n",
      "Precision: 0.92\n",
      "Recall: 0.55\n",
      "f1 score: 0.69\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.81\n",
      "True Positive Rate: 0.60\n",
      "False Positive Rate: 0.05\n",
      "True Negative Rate: 0.95\n",
      "Flase Negative Rate: 0.40\n",
      "Precision: 0.90\n",
      "Recall: 0.60\n",
      "f1 score: 0.72\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.81\n",
      "True Positive Rate: 0.64\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.36\n",
      "Precision: 0.87\n",
      "Recall: 0.64\n",
      "f1 score: 0.74\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.84\n",
      "True Positive Rate: 0.70\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.30\n",
      "Precision: 0.86\n",
      "Recall: 0.70\n",
      "f1 score: 0.78\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.69\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.31\n",
      "Precision: 0.87\n",
      "Recall: 0.69\n",
      "f1 score: 0.77\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.67\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.33\n",
      "Precision: 0.87\n",
      "Recall: 0.67\n",
      "f1 score: 0.76\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.69\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.31\n",
      "Precision: 0.87\n",
      "Recall: 0.69\n",
      "f1 score: 0.77\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.69\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.31\n",
      "Precision: 0.87\n",
      "Recall: 0.69\n",
      "f1 score: 0.77\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.83\n",
      "True Positive Rate: 0.67\n",
      "False Positive Rate: 0.07\n",
      "True Negative Rate: 0.93\n",
      "Flase Negative Rate: 0.33\n",
      "Precision: 0.87\n",
      "Recall: 0.67\n",
      "f1 score: 0.76\n",
      "Positive support: 172\n",
      "Negative support: 254\n",
      "-----------------------------------------\n",
      "best model had  1  for min_samples_leaf and 10 for max_depth\n"
     ]
    }
   ],
   "source": [
    "best_i = 0\n",
    "best_j = 0\n",
    "best_acc = 0\n",
    "\n",
    "for i in range(1,11):\n",
    "    for j in range(1,11):\n",
    "        rf = RandomForestClassifier(min_samples_leaf=i,\n",
    "                            max_depth=j, \n",
    "                            random_state=123)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_train)\n",
    "\n",
    "        cm = confusion_matrix(y_train, y_pred)\n",
    "        model_scores(cm, i, j)\n",
    "        \n",
    "        if rf.score(X_train, y_train) > best_acc:\n",
    "            best_acc = rf.score(X_train, y_train)\n",
    "            best_i = i\n",
    "            best_j = j\n",
    "            \n",
    "print('best model had ', best_i,' for min_samples_leaf and', best_j, 'for max_depth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c41af03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model performs best on training data when minimum leaf samples is lower and max depth is higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ee0f5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.86\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.86\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 1\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.86\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 2\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.86\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 3\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.86\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 4\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.87\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 5\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.81\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 6\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.81\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.81\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 7\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.81\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.81\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 8\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.82\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.84\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 9\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 1\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 2\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 3\n",
      "\n",
      "Accuracy: 0.85\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 4\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 5\n",
      "\n",
      "Accuracy: 0.82\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 6\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 7\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 8\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 9\n",
      "\n",
      "Accuracy: 0.83\n",
      "Model stats for Random Forest with:\n",
      "\n",
      "     min_samples_leaf = 10\n",
      "        and max_depth = 10\n",
      "\n",
      "Accuracy: 0.83\n",
      "best model had  4  for min_samples_leaf and 3 for max_depth\n",
      "And an accuracy of 0.8741258741258742\n"
     ]
    }
   ],
   "source": [
    "best_i = 0\n",
    "best_j = 0\n",
    "best_acc = 0\n",
    "\n",
    "for i in range(1,11):\n",
    "    for j in range(1,11):\n",
    "        # create and fit the classifier using train\n",
    "        rf = RandomForestClassifier(min_samples_leaf=i,\n",
    "                            max_depth=j, \n",
    "                            random_state=123)\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        # create predictions and scores using validate\n",
    "        y_pred = rf.predict(X_validate)\n",
    "\n",
    "        cm = confusion_matrix(y_validate, y_pred)\n",
    "        model_scores(cm, i, j)\n",
    "        \n",
    "        if rf.score(X_validate, y_validate) >= best_acc:\n",
    "            best_acc = rf.score(X_validate, y_validate)\n",
    "            best_i = i\n",
    "            best_j = j\n",
    "            \n",
    "print('best model had ', best_i,' for min_samples_leaf and', best_j, 'for max_depth')\n",
    "print('And an accuracy of', best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d30cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when using validation data the best model was the one with 4 min samples per leaf, and max depth of 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "05be5fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model had  8  for min_samples_leaf and 4 for max_depth\n",
      "With a validate accuracy of 0.8181818181818182\n",
      "With an accuracy difference of 0.0010670081092615247\n"
     ]
    }
   ],
   "source": [
    "# comparing the two\n",
    "\n",
    "best_i = 0\n",
    "best_j = 0\n",
    "best_dif = 100\n",
    "best_acc = 0\n",
    "\n",
    "for i in range(1,11):\n",
    "    for j in range(1,11):\n",
    "        # create and fit the classifier using train\n",
    "        rf = RandomForestClassifier(min_samples_leaf=i,\n",
    "                            max_depth=j, \n",
    "                            random_state=123)\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        y_train_pred = rf.predict(X_train)\n",
    "        y_val_pred = rf.predict(X_validate)\n",
    "\n",
    "        cm_train = confusion_matrix(y_train, y_train_pred)\n",
    "        cm_validate = confusion_matrix(y_validate, y_val_pred)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if abs((rf.score(X_train, y_train)) - (rf.score(X_validate, y_validate))) < best_dif:\n",
    "            best_dif = abs((rf.score(X_train, y_train)) - (rf.score(X_validate, y_validate)))\n",
    "            best_i = i\n",
    "            best_j = j\n",
    "            \n",
    "            best_acc = rf.score(X_validate, y_validate)\n",
    "            \n",
    "print('best model had ', best_i,' for min_samples_leaf and', best_j, 'for max_depth')\n",
    "print('With a validate accuracy of', best_acc)\n",
    "print('With an accuracy difference of', best_dif)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9a989",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
